{"cells":[{"cell_type":"markdown","metadata":{"id":"MDwgqVp3XVVR"},"source":["# Detección de salto de línea de lectura en tiempo real"]},{"cell_type":"markdown","metadata":{"id":"gianjmvZaNw7"},"source":["## Importaciones"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4475,"status":"ok","timestamp":1644673357300,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"vxB5cExOQV05"},"outputs":[],"source":["from keras.models import load_model\n","import numpy as np\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","from matplotlib.figure import Figure"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17270,"status":"ok","timestamp":1644673374564,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"y8aNBWPhQuar","outputId":"e9222147-12eb-4dcc-da9c-337ea54cfce3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"NveXwl1EaJ29"},"source":["## Definiciones y métodos"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1644677216156,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"L8Mp3FN_QZy0"},"outputs":[],"source":["def detecta_ojo(frame, face_cascade, eye_cascade, ojo_a_analizar=\"D\", restringir_detectar_dos_ojos=True):\n","    \"\"\"Devuelve la imagen del ojo derecho encontrado, en otro caso, devuelve el frame.\"\"\"\n","    \n","    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n","\n","    if len(faces) > 0:\n","        x, y, w, h = faces[0]\n","        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 5)\n","        face_img = frame[y:y+w, x:x+w]\n","        eyes = eye_cascade.detectMultiScale(face_img, 1.3, 5)\n","\n","        if len(eyes) < 2 and restringir_detectar_dos_ojos: # Si no detecta los 2 ojos, que coja el frame anterior.\n","            return (False, frame)\n","\n","        if len(eyes) > 0:\n","            \n","            pos_ojo = get_posicion_ojo(ojo_a_analizar, eyes, faces[0])\n","\n","            ex, ey, ew, eh = eyes[pos_ojo]\n","            eye_img = face_img[ey:ey+eh,ex:ex+ew]\n","\n","            return (True, eye_img)\n","\n","    return (False, frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1644677220545,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"5TccUEiLQclQ"},"outputs":[],"source":["def get_posicion_ojo(tipo_ojo, ojos_detectados, cara):\n","    \"\"\"Devuelve la posición del ojo deseado (izquierdo en el vídeo o derecho) en ojos_detectados.\"\"\"\n","    \n","    x, y, w, h = cara\n","    pos_ojo=0\n","    x_ojo=0\n","\n","    isOjoALaDerecha = tipo_ojo == \"D\"\n","    isOjoALaIzquierda = tipo_ojo == \"I\"\n","\n","    if isOjoALaIzquierda:\n","        x_ojo=x+w\n","\n","    for i in range(len(ojos_detectados)):\n","\n","        if isOjoALaIzquierda and ojos_detectados[i][0] < x_ojo:\n","            x_ojo=ojos_detectados[i][0]\n","            pos_ojo=i\n","\n","        if isOjoALaDerecha and ojos_detectados[i][0] > x_ojo:\n","            x_ojo=ojos_detectados[i][0]\n","            pos_ojo=i\n","\n","    return pos_ojo"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1644677226996,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"I0DcEjS-Qgfe"},"outputs":[],"source":["def hasBreakLine(modelo_final, frames_ojo_list):\n","    '''Devuelve true si se trata de una línea leída.'''\n","    \n","    x_test_prueba_set = np.array([frames_ojo_list])\n","    \n","    results = np.argmax(modelo_final.predict(x_test_prueba_set), axis = 1)\n","\n","    return results[0] == 1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":388,"status":"ok","timestamp":1644677228458,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"UD_3RJhZT9Bs"},"outputs":[],"source":["def getImageShape(image):\n","  \"\"\"Devuelve las dimensiones de la imagen.\"\"\"\n","  \n","  height, width = image.shape[:2]\n","\n","  return height, width"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1644677230502,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"vfBp3V3qb7a3"},"outputs":[],"source":["def changeImageColor(target_img):\n","  \"\"\"Devuelve una imagen con un filtro de color aplicado.\"\"\"\n","  \n","  #target_img = cv2.cvtColor(target_img,cv2.COLOR_GRAY2RGB) # Aplicar solo si la imagen de entrada está en escala de grises.\n","  \n","  # Creamos dos copias de la imagen:\n","  # · Una para la capa de encima.\n","  # · Otra para la salida.\n","  overlay = target_img.copy()\n","  output = target_img.copy()\n","\n","  img_h, img_w = getImageShape(target_img)\n","\n","  # Dibujamos un rectángulo en la imagen.\n","\n","  cv2.rectangle(overlay, (0, 0), (img_w, img_h), (0, 255, 0), -1)\n","  \n","  # Aplicamos la capa.\n","  cv2.addWeighted(overlay, 0.4, output, 1 - 0.4, 0, output)\n","\n","  return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":251,"status":"ok","timestamp":1644678293339,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"m4XcKeUtQNkz"},"outputs":[],"source":["def addInfoLineasLeidas(target_img, numLineasLeidas, segundoEnCurso):\n","    \"\"\"Devuelve una imagen con la info de líneas leidas y segundos del vídeo.\"\"\"\n","\n","    # Creamos dos copias de la imagen:\n","    # · Una para la capa de encima.\n","    # · Otra para la salida.\n","    overlay = target_img.copy()\n","    output = target_img.copy()\n","\n","    blue=188.955\n","    green=113.985\n","    red=0\n","\n","    font_size=0.8\n","    font_weight=2\n","\n","    # Añadimos el texto.\n","    cv2.putText(overlay, f\"{numLineasLeidas} LINEAS LEIDAS EN {segundoEnCurso} SEGUNDOS\", \n","                (20, 60), cv2.FONT_HERSHEY_COMPLEX, font_size, (blue, green, red), font_weight)\n","\n","    cv2.putText(overlay, f\"TASA: {tasaLeidoSegundo(numLineasLeidas, segundoEnCurso)} LINEAS/SEGUNDO\", \n","                (20, 100), cv2.FONT_HERSHEY_COMPLEX, font_size, (blue, green, red), font_weight)\n","    \n","    alpha=0.8\n","\n","    # Aplicamos la capa.\n","    cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n","\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1644673374570,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"J5RlrRzSReem"},"outputs":[],"source":["def cargaVideo(video_path):\n","  '''Obtiene el vídeo, los FPS y la duración.'''\n","\n","  video = cv2.VideoCapture(video_path)\n","  fps = video.get(cv2.CAP_PROP_FPS)\n","  frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n","  seconds = int(frames / fps)\n","\n","  width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","  height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","  return video, fps, seconds, width, height"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1644673374571,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"FHAxh2LCU8-r"},"outputs":[],"source":["def reescalaFrame(frame):\n","    \"\"\"Devuelve el frame reescalado para el trabajo con la red.\"\"\"\n","\n","    frame_reescalado = cv2.resize(frame,(800,600),fx=0,fy=0, interpolation = cv2.INTER_AREA)\n","\n","    return frame_reescalado"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1644673374571,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"PPXjHECgWmTd"},"outputs":[],"source":["def reescalaOjo(frame_ojo):\n","    '''Devuelve el frame del ojo reescalado para el trabajo con el modelo.'''\n","\n","    frame_ojo_reescalado = cv2.resize(frame_ojo, (80, 80), interpolation=cv2.INTER_AREA)  \n","\n","    return frame_ojo_reescalado  "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1644673374572,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"IXek7nIvVKTN"},"outputs":[],"source":["def frameToGrayScale(frame):\n","    \"\"\"Devuelve el frame en escala de grises para el trabajo con la red.\"\"\"\n","\n","    frame_escala_grises = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    return frame_escala_grises"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1644673374573,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"tb7hdvfexB9_"},"outputs":[],"source":["def framesADescartar(fps, num_frames_borrar):\n","    \"\"\"Devuelve un listado de frames a descartar del video.\"\"\"\n","    \n","    framesDescartados = set()\n","\n","    if num_frames_borrar!=0:\n","        periodo = round(fps) / num_frames_borrar\n","\n","        for i in range(num_frames_borrar):\n","            frame_descartado=round(i*periodo)\n","            framesDescartados.add(frame_descartado)\n","\n","    return framesDescartados"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1644677238244,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"gN1QZXaCrTYH"},"outputs":[],"source":["def tasaLeidoSegundo(numLineasLeidas, segundoEnCurso):\n","    \"\"\"Devuelve la tasa de líneas leídas por segundo.\"\"\"\n","\n","    tasa = segundoEnCurso\n","    \n","    if segundoEnCurso != 0:\n","        tasa = round(numLineasLeidas/segundoEnCurso, 3)\n","\n","    return tasa"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1644677240271,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"Shw4TjM4t1f2"},"outputs":[],"source":["def generateReadingRateChart(numLineasLeidas, lineas_por_segundo, totalSegundos):\n","    \"\"\"Devuelve el gráfico de líneas/segundo.\"\"\"\n","    \n","    # Creamos la figura que contendrá el gráfico.\n","    fig = plt.figure()\n","\n","    # Gráfico de evolucion del rendimiento del lector.\n","    x = range(len(lineas_por_segundo))\n","    plt.plot(x, lineas_por_segundo, label='Líneas leídas/segundo')\n","    plt.legend(loc=\"lower right\")\n","\n","    plt.ylim(0, 1)\n","    \n","    # Hacemos que muestre todos los segundos del vídeo en el gráfico, \n","    # aunque no se le estén pasando todas las x todavía.\n","    plt.xlim([0, totalSegundos])\n","    plt.xticks((range(totalSegundos)[0::10]))\n","\n","    # Convertimos el gráfico al tipo de imagen admitida por OpenCV: numpy array.\n","    canvas = FigureCanvas(fig)\n","    canvas.draw()\n","\n","    # Convertimos el cancas a una imagen.\n","    graph_image = np.array(fig.canvas.get_renderer()._renderer)\n","\n","    # La imagen es del tipo RGB. OpenCV trabaja por defecto con BGR, por lo que la convertimos.\n","    chart_image = cv2.cvtColor(graph_image,cv2.COLOR_RGB2BGR)\n","    \n","    # Cerramos la figura para prevenir llenar la memoria.\n","    plt.close(fig)\n","\n","    return chart_image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1644677242563,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"rgB0Rn0CVOOP"},"outputs":[],"source":["def addImageToFrame(current_frame, image_watemark):\n","    \"\"\"Añade una imagen superpuesta al frame de entrada.\"\"\"\n","\n","    # Escalamos la imagen de entrada.\n","    watemark_scale = 70\n","\n","    wm_width = int(image_watemark.shape[1] * watemark_scale/100)\n","    wm_height = int(image_watemark.shape[0] * watemark_scale/100)\n","    wm_dim = (wm_width, wm_height)\n","\n","    resized_wm = cv2.resize(image_watemark, wm_dim, interpolation=cv2.INTER_AREA)\n","\n","    img_height, img_width = getImageShape(resized_wm)\n","\n","    # Establecemos las coordenadas donde meter la imagen superpuesta.\n","    top_y = 500\n","    left_x = 20\n","    bottom_y = top_y + img_height\n","    right_x = left_x + img_width\n","\n","    # Añadimos la imagen al frame.\n","    current_frame[top_y:bottom_y, left_x:right_x] = resized_wm\n","\n","    return current_frame"]},{"cell_type":"markdown","metadata":{"id":"ou6shXrRaEI4"},"source":["## Ejecución del programa"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1644677245480,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"pMKeLfLqQlx1"},"outputs":[],"source":["# datetime object containing current date and time\n","now = datetime.now()\n","\n","# Parámetros de entrada.\n","video_path = \"/path/Saturdays AI - Equipo ojo/Videos/v_persona_01.mp4\"\n","ai_model_path = '/path/Saturdays AI - Equipo ojo/modeloEntrenado'\n","video_output_path = f'/path/Saturdays AI - Equipo ojo/video_results/video_output-{now.strftime(\"%d-%m-%Y_%H-%M-%S\")}.mp4'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61280,"status":"ok","timestamp":1644673436193,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"h5fMiHJqR5qQ","outputId":"86b8c0be-25a7-4fb2-cde8-100e770e0e03"},"outputs":[],"source":["# Cargamos el modelo con el que predecir los saltos de línea.\n","modelo_final = load_model(ai_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288939,"status":"ok","timestamp":1644678659643,"user":{"displayName":"Juan Bautista García","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08757908812281874002"},"user_tz":-60},"id":"HhVOGVM6SSuW","outputId":"dcd4c1ee-931d-48b9-deeb-3d2ad2c638cc"},"outputs":[],"source":["# Cargamos los clasificadores.\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n","\n","# Obtenemos el vídeo y metadatos.\n","video, fps, segundos, width, height = cargaVideo(video_path)\n","\n","# Reescalamos el vídeo a los fps de la red.\n","num_frames_borrar=round(fps)-10\n","framesDescartados = framesADescartar(fps, num_frames_borrar)\n","\n","# Establecemos el vídeo de salida con los mismos parámetros que el de entrada.\n","video_output = cv2.VideoWriter(video_output_path, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 10.0, (width, height))\n","\n","# Variables de entorno.\n","frame_ojo_prev=[]\n","frames_ojo_list=[]\n","frames_list=[]\n","frame_counter = 0\n","num_frame_por_segundo=0\n","num_segundo=0\n","num_lineas_leidas=0\n","lines_per_second=[]\n","\n","while video.isOpened():\n","\n","    hasFrame, frame = video.read()\n","\n","    if not hasFrame:\n","      break\n","\n","    print(f\"\\rVoy por el frame {frame_counter} de {(segundos*fps)}.\", end=\"\")\n","    \n","    frame_counter+=1\n","\n","    num_frame_por_segundo=(num_frame_por_segundo+1)%round(fps)\n","\n","    if num_frame_por_segundo in framesDescartados:\n","      continue\n","    \n","    frame_reescalado = reescalaFrame(frame)\n","    frame_escala_grises = frameToGrayScale(frame_reescalado)\n","\n","    ojo_detectado, frame_ojo = detecta_ojo(frame_escala_grises, face_cascade, eye_cascade)\n","\n","    # Si no obtenemos ojo en este frame, recuperamos el anterior.\n","    if not ojo_detectado and len(frame_ojo_prev) > 0: \n","        frame_ojo = frame_ojo_prev\n","\n","    frame_ojo_reescalado = reescalaOjo(frame_ojo)\n","\n","    frames_ojo_list.append(frame_ojo_reescalado)\n","    frames_list.append(frame)\n","\n","    # Acumulamos los 10 frames con los que trabaja el modelo.\n","    if len(frames_ojo_list) == 10:\n","\n","        isBreakLine = hasBreakLine(modelo_final, frames_ojo_list)\n","        \n","        if isBreakLine:\n","            num_lineas_leidas+=1\n","\n","        for i in range(len(frames_ojo_list)):\n","          current_frame = frames_list[i]\n","\n","          # Realizamos las modificaciones sobre el frame.\n","          if isBreakLine:\n","            current_frame = changeImageColor(current_frame)\n","                    \n","          current_frame = addInfoLineasLeidas(current_frame, num_lineas_leidas, num_segundo)\n","\n","          lines_per_second_chart = generateReadingRateChart(num_lineas_leidas, lines_per_second, segundos)\n","\n","          current_frame = addImageToFrame(current_frame, lines_per_second_chart)\n","\n","          # Grabamos el frame en el nuevo vídeo.\n","          video_output.write(current_frame)\n","\n","        # Reseteamos variables de entorno.\n","        frames_ojo_list = []\n","        frames_list = []\n","        lines_per_second.append(tasaLeidoSegundo(num_lineas_leidas, num_segundo))\n","        num_segundo+=1\n","\n","    frame_ojo_prev = frame_ojo\n","\n","# Finalizamos ejecución y guardamos el vídeo\n","video.release()\n","video_output.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"deteccion_salto_linea_localvideo_resalte_color.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
